%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is just an example/guide for you to refer to when submitting manuscripts to Frontiers, it is not mandatory to use Frontiers .cls files nor frontiers.tex  %
% This will only generate the Manuscript, the final article will be typeset by Frontiers after acceptance.   
%                                              %
%                                                                                                                                                         %
% When submitting your files, remember to upload this *tex file, the pdf generated with it, the *bib file (if bibliography is not within the *tex) and all the figures.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Version 3.4 Generated 2018/06/15 %%%
%%% You will need to have the following packages installed: datetime, fmtcount, etoolbox, fcprefix, which are normally inlcuded in WinEdt. %%%
%%% In http://www.ctan.org/ you can find the packages and how to install them, if necessary. %%%
%%%  NB logo1.jpg is required in the path in order to correctly compile front page header %%%

\documentclass[utf8, a4paper, final, crop]{frontiersSCNS}
\usepackage[switch,columnwise]{lineno}

\usepackage{url,lineno,microtype,subcaption}


\usepackage[onehalfspacing]{setspace}

\usepackage{fontspec} 
\setmainfont[Mapping=tex-text]{Times New Roman}

\usepackage{minted}  % for styling python code
\newcommand{\pythoninline}[1]{\mintinline{python}{#1}}
\newcommand{\bashinline}[1]{\mintinline{bash}{#1}}

\usepackage{hyperref}
\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = blue, %Colour for external hyperlinks
  linkcolor    = blue, %Colour of internal links
  citecolor    = red, %Colour of citations
  filecolor	   = magenta,      
  pdftitle	   = {Sammba-MRI},
  bookmarks    = true
}


\linenumbers

\def\keyFont{\fontsize{8}{11}\helveticabold }
\def\firstAuthorLast{Bougacha {et~al.}}
\def\Authors{Salma Bougacha\,$^{1,2,3,4}$, Nachiket A. Nadkarni\,$^{1,2}$, 
Marina Celestine\,$^{1,2}$, Cl\'ement M. Garin\,$^{1,2}$, and Marc 
Dhenain\,$^{1,2,*}$}

\def\Address{$^{1}$UMR9199 Laboratory of Neurodegenerative Diseases Mechanisms, Centre National de la Recherche Scientifique (CNRS), Fontenay-aux-Roses, France

$^{2}$MIRCen, Institut Fran\c{c}ois Jacob, Commissariat \`a l'Energie Atomique et aux Energies Alternatives (CEA), Fontenay aux Roses, France 

$^{3}$UMR-S U1237 Physiopathologie et imagerie des troubles Neurologiques (PhIND), INSERM, Universit\'e de Caen-Normandie, GIP Cyceron, Caen, France 

$^{4}$Normandie Universit\'e, UNICAEN, PSL Research University, EPHE, Inserm, U1077, CHU de Caen, Neuropsychologie et Imagerie de la M\'emoire Humaine, Caen, France
}

\def\corrAuthor{Marc Dhenain, MIRCen, UMR CEA-CNRS 9199, 18 Route du Panorama,92265 Fontenay-aux-Roses CEDEX, France}

\def\corrEmail{marc.dhenain@cea.fr}

\begin{document}
\firstpage{1}

\title[Sammba-MRI]{Sammba-MRI: a library for processing SmAll MaMmals BrAin MRI data in Python} 


\author[\firstAuthorLast ]{\Authors} %This field will be automatically populated
\address{} %This field will be automatically populated
\correspondance{} %This field will be automatically populated

\extraAuth{}

\maketitle

\begin{abstract}

Small mammals neuroimaging offers incredible opportunities to investigate structural and
functional aspects of the brain. Many tools have been developed in the last decade to analyse
small animal data, but current softwares are less mature than the available tools that process
human brain data. The Python package Sammba-MRI (SmAll MaMmals BrAin MRI in Python;
\url{http://sammba-mri.github.io}) is designed to allow flexible and efficient use of existing methods and
enables fluent scriptable analysis workflows, from raw data conversion to multimodal
processing.

%includes automated pre-processing steps, such as raw data conversion, skull-stripping and bias-field correction as well as image registration with the Allen Brain Reference Atlas (ARA)

%%% Leave the Abstract empty if your article does not require one, please see the Summary Table for full details.
%For full guidelines regarding your manuscript please refer to \href{http://www.frontiersin.org/about/AuthorGuidelines}{Author Guidelines}.
%As a primary goal, the abstract should render the general significance and conceptual advance of the work clearly accessible to a broad readership. References should not be cited in the abstract. Leave the Abstract empty if your article does not require one, please see \href{http://www.frontiersin.org/about/AuthorGuidelines#SummaryTable}{Summary Table} for details according to article type. 


\tiny
 \keyFont{ \section{Keywords:} Processing pipeline, MRI, registration, small animal Neuroimaging, Python } 


\end{abstract}

\section{Introduction}

The use of magnetic resonance imaging (MRI) methods in animals
provides considerable benefits for improving our understanding
of the brain structure and functioning in health and disease.
The greatest advantages of preclinical MRI include
group homogeneity and the opportunity to acquire a high amount of information
repeated or modulated as needed.
This added value, together with practical and ethical considerations,
resulted in an increase of the use of small mammals MRI in research.
%
% is particularly increasing in research and pharmaceutical companies
% Practical and ethical considerations
%
%their use in research is accompanied by a host of practical challenges and ethical considerations.
%
% from Preclinical imaging: an essential ally in modern biosciences.
%The development of high-resolution in vivo imaging technologies provides a unique opportunity for studying disease in real time, in a quantitative way, at the molecular level, along with the ability to repeatedly and non-invasively monitor disease progression or response to treatment. The greatest advantages of preclinical imaging techniques include the reduction of biological variability and the opportunity to acquire, in continuity, an impressive amount of unique information (without interfering with the biological process under study) in distinct forms, repeated or modulated as needed, along with the substantial reduction in the number of animals required for a particular study, fully complying with 3R (Replacement, Reduction and Refinement) policies. The most suitable modalities for small-animal in vivo imaging applications are based on nuclear medicine techniques (essentially, positron emission tomography [PET] and single photon emission computed tomography [SPECT]), optical imaging (OI), computed tomography (CT), magnetic resonance imaging (MRI), magnetic resonance spectroscopy imaging (MRSI), and ultrasound. Each modality has intrinsic advantages and limitations. More recently, aiming to overcome the inherent limitations of each imaging modality, multimodality devices designed to provide complementary information upon the pathophysiological process under study have gained popularity. The combination of high-resolution modalities, like micro-CT or micro-MRI, with highly sensitive techniques providing functional information, such as micro-PET or micro-SPECT, will continue to broaden the horizons of research in such key areas as infection, oncology, cardiology, and neurology, contributing not only to the understanding of the underlying mechanisms of disease, but also providing efficient and unique tools for evaluating new chemical entities and candidate drugs. The added value of small-animal imaging techniques has driven their increasing use by pharmaceutical companies, contract research organizations, and research institutions.
However, while human brain imaging benefits from a large variety of high 
level software solutions 
%optimized for the size and spatial features of the human brain.
for MRI preprocessing and analysis, preclinical MRI
is left behind.
There is currently an urgent need for % calls
efficient and collaborative tools that would facilitate the adoption and 
dissemination of standardized pre-processing strategies for small animal MRI.

%Challenges in small animal magnetic resonance imaging (MRI) include . Technical advances entail increasing data resolution, sample size, and meta-information complexity. The changing data properties call for more advanced statistical methods that scale naturally to the high-dimensional regime, are inter-operable in complex processing pipelines, and can better exploit modern multiprocessing architectures than predominant methods.
%
%For Original Research Articles , Clinical Trial Articles, and Technology Reports , the introduction should be succinct, with no subheadings. For Case Reports the Introduction should include symptoms at presentation, physical exams and lab results.
%

\section{Tools: Python ecosystem and neuroimaging software packages}

With its Free and Open Source Software (FOSS)
dependency stack and its growing neuroimaging community 
%with tools such as Nipy (Millman and Brett, 2007), 
Python has been naturally the language of choice for our
package.
%
%The language of choice for workflow handling is Python, owing to its Free and Open Source (FOSS) dependency stack, readability, wealth of available libraries, ease of package management, and its large and dynamic developer community. 
%
%Python is a growing contender in the landscape of neuroimaging data analysis with tools such as Nipy (Millman and Brett, 2007). 
%
The scientific Python libraries used in Sammba-MRI are
NumPy \citep{oliphant2006guide}, SciPy \citep{millman2011python}, the neuroimaging 
data analysis tools nibabel \citep{nibabel}, Nilearn \citep{abraham2014machine} and 
Nipype \citep{gorgolewski2011Nipype}. %as well as
Visualization functionality depends on Matplotlib \citep{hunter2007matplotlib} 
or Graphviz \citep{gansner2000open}, but neither is required to perform
MRI data processing.

Via Nipype, we utilize basic MRI preprocessing
functions from AFNI \citep{cox1996afni}, FSL \citep{jenkinson2012fsl} and ANTs 
\citep{avants2009advanced}
packages. The dependency on the efficient but non open-source brain segmentation RATs 
tool \citep{oguz2014rats} is optional.

%Visualization functionality depends on Mat-plotlib (Hunter, 2007) and/or Graphviz (Gansner and North, 2000), but neither is required to perform machine learning or prediction. 
%
%For requirements for a specific article type please refer to the Article Types on any Frontiers journal page. Please also refer to  \href{http://home.frontiersin.org/about/author-guidelines#Sections}{Author Guidelines} for further information on how to organize your manuscript in the required sections or their equivalents for your field
% For Original Research articles, please note that the Material and Methods section can be placed in any of the following ways: before Results, before Discussion or after Discussion.
%

\section{Code design}

Coding guidelines follow the %recommendations of \citet{varoquaux2010software}
practices of Nilearn and other successfully adopted packages
\citep[e.g. Scikit-learn][]{pedregosa2011scikit} 
%and \citeauthor{joblib}
to make the codebase understandable and easily maintainable\footnote{\url{http://gael-varoquaux.info/programming/software-design-for-maintainability.html}}.
% Emphasis is put on ease of use, performance, documentation, and API consistency
%
%minimal dependencies, sparse use of objects while making many different classes that share the same interface.
%
%Consistency, minimal classes, sklearn nomenclature, minimal dependencies
%
Objects are used with parsimony : the different registration classes share
all the same interface, and the brain extraction
classes comply to the Nipype \pythoninline{BaseInterface}.
Effort is made to keep the code uniformly formatted and to use consistent 
naming for the functions and parameters 
%nomenclature 
following the coding conventions of Nilearn.
%use consistent naming for the  functions and parameters used throughout a strict adherence to the Python coding guidelines and numpy style documentation
%The dependencies are kept to the possible minimum to facilitate the installation
% Finally,  we strive to use consistent naming for the functions and parameters used throughout a strict adherenceto the Python coding guidelines and numpy style documentation 
%Graphical or interactive interfaces are avoided, as they impede reproducibility, encumber the dependency graph, and reduce the sustainability of the project.
Preprocessing building blocks and pipelines are automatically tested on light MRI 
data samples to ensure code quality.
%Code  quality  is  ensured  with  unit  tests—as  of  release  0.8,  testcoverage is 81%—
%
Finally, the user is guided through Sammba-MRI with 
extensive documentation including installation instructions, API reference,
pipelines graphs, and practical examples based on publicly available small animal 
neuroimaging datasets.
%
%Sammba-MRI provides practical examples to shows how to use the implemented methods. 
%including narrative documentation, class references, a tutorial, installation instructions, as well as more than 60 examples, some featuring real-world applications. We try to minimize the use of machine-learning jargon, while maintaining precision with regards to the algorithms employed.
%
%By relying on publicly available small animal neuroimaging dataset, Sammba-MRI provides practical examples to shows how to use the implemented methods. 
%
%All pipelines rely on scikit-learn transformers.

\section{Preprocessing bricks}

\subsection{DICOM to NIfTI conversion}

Sammba-MRI allows to convert Bruker DICOM (digital imaging and communications in medicine) files to the standard  Neuroimaging Informatics Technology Initiative  format (NIfTI-1) and extracts extensive information using DCMTK package  \citep{eichelberg2004ten}. 
Bruker files conversion is an active development field,
with various available tools handling DICOM (e.g. 
dicomifier\footnote{\url{https://github.com/lamyj/dicomifier}}) or
not (e.g. bru2nii\footnote{\url{https://github.com/neurolabusc/Bru2Nii}},
Bruker2nifti\footnote{\url{https://github.com/CristinaChavarrias/Bruker2nifti}}, bruker2nifti\footnote{\url{https://github.com/SebastianoF/bruker2nifti}}).
Finally, ParaVision 360 with the latest patch 1.1 can export the NIFTI format since February 2019.
%Finally, ParaVision can export the NIFTI format. But, one needs to upgrade to ParaVision 360 with the latest patch 1.1. Most users using PV 6 are still left behind. So, Bru2Nii is still needed before Bruker upgrading PV 6 to support NIFTI.
Our implementation is meant to be a light helper function, allowing to 
handle the conversion on the fly. It has been tested only for Paravision 6
and a limited number of imaging sequences.

\subsection{Bias field correction}

Intensity non-uniformity modelling is essential in preclinical studies
because the intensity gradient corrupting MR images becomes
particularly pronounced at high field strengths \citep{boyes2008intensity}.
Sammba-MRI relies on AFNI's \bashinline{3dUnifize} to correct for intensity bias in
anatomical images, and on \bashinline{N4BiasFieldCorrection} function
of the ANTs package \citep{tustison2010n4itk}
for the other modalities. 3dUnifize is also used to aid brain extraction,
as detailed in the following paragraph.

% from Power Phd
%A smoothly-varying, hardware-induced, low-frequency intensity gradient often corrupts MR images (Sled & Pike, 1998). This is caused by inhomogeneity of the scanner’s B0 field, variable sensitivity of the receiver coils, or inhomogeneity of the radiofrequency pulse, which can be induced via non-uniformity of the transmission coil or via electromagnetic interactions and distortions by the subjects themselves (Lewis & Fox, 2004). As this effect becomes especially pronounced at high field strengths (Boyes et al.,2008), intensity non-uniformity modelling is essential in preclinical studies. NUC improves automated tissue classifications and image registration (Sled & Pike, 1998; Van Leemput et al., 1999; Lewis & Fox, 2004). Locally adaptive NUC algorithms, such as N3, have been shown to outperform nonadaptive methods (Arnold et al., 2001). I initially employed N3 (Sled et al., 1998), and later the N4ITK (N4) algorithm (Tustison et al., 2010), found to reliably correct bias at high field strengths, using 200 iterations; 256 histogram bins; a 0.15mm FWHM Gaussian kernel to model the bias field; subsampling factor 4 (for high-resolution, ex vivo images) or 2 (for lower-resolution in vivo images). NUC is further refined during the iterative expectation maximisation steps of tissue segmentation. In neither technique is the image resampled; thus image quality is maintained.

\subsection{Skull-stripping}

Skull-stripping is the critical early step in processing
MRI images from small animals. Various automatic rodent-specific 
softwares \citep{chou2011robust, oguz2014rats} or adaptations of human algorithms (\citeauthor{wood2013rbet}, \citeyear{wood2013rbet}; AFNI's 3dskullstrip -rat)
are freely available for research purposes. We choose to rely on
the LOGISMOS-based graph segmentation \citep{yin2010logimos} based on grayscale mathematical morphology 
%Oguz et al. (2014) followed mathematical morphology operations with an intensity gradient-based graph cut method to constrain the outer surface of a rodent brain mask. This required varying smoothness constraints across the resulting brain surface, and a manually-specified upper bound on the brain volume. 
RATS software  \citep{oguz2014rats} because
of its good performance across a wide range of datasets \citep{sargolzaei2018comparative}.
%and the template-based skullstripper \citep{delora2016simple}.
An alternative to the free but non-open source RATS tool is also 
available, based on an adaptation of the 
human histogram-based brain extraction method of Nilearn. 
This method can be used in any pipeline by setting the parameter
 \pythoninline{use_rats_tool} to \pythoninline{False}.
Because intensity inhomogeneity can hamper the performance of automatic skull stripping,
prior bias field correction
is usually recommended \citep{sled1998nonparametric} and is performed by default with \bashinline{3dUnifize}.
The helper function \pythoninline{brain_segmentation_report}
from Sammba-MRI \pythoninline{segmentation} module allows to
efficiently tune the initial intensity threshold used in bias correction by
producing for a given set of thresholds 5 informative measures
characterizing the extracted mask to bypass %for [a wide range] of thresholds 
time consuming repetitive visual checks.
The returned features %reflect the masking] quality and 
consist of the total volume of
the extracted mask, its 
anteroposterior length, its right-left width, and its inferior-superior hight as well
as the sample Pearson's product-moment correlation
coefficient between the brain mask image and its reflection
with respect to the estimated mid-sagittal plane
%its symmetry in the mid-sagittal plane 
%inspired from 
\citep{powell2016fully}.

\section{Ready-to-use pipelines}

Sammba-MRI proposes optimized pipelines to perform spatial registration
to a population or standard reference template, inter-modalities
registration and functional and perfusion MRI processing.
State-of-the-art small animal registration pipelines available as FOSS
are the Atlas-based Imaging Data Analysis of structural and functional mouse
brain MRI (AIDAmri) \citep{pallast2019processing} package for the registration of functional and diffusion
mouse brain MRI with the Allen Brain Reference atlas and
the mouse-brain-optimized registration workflow \citep{ioanas2019optimized}
part of SAMRI package. 
Sammba-MRI pipelines have been tested throughout the different stages of their
development process on various datasets from mouse, rat and mouse lemur
and used in several publications from our lab \citep{garin2018resting, nadkarni20193d, garin2019resting}.
%Although there is no conceptual reason preventing their usability on MRI brain data from other small mammals like the common marmoset, they never not been tested on such images due to the lack of publicly available datasets.
All pipelines start with bias filed correction for the individual images.
The registration itself relies on AFNI's \bashinline{3dAllineate} and \bashinline{3dQwarp} functions to 
estimate linear and nonlinear (piecewise polynomial $C^1$ diffeomorphism) transforms respectively between the source image
and the reference image. Internal parameters of these functions have been optimized for
small animal brains.
We experienced a better performance when linear registration
is performed on brain extracted images and nonlinear warps are computed
using whole head images, and therefore followed this strategy across all the 
registration pipelines.

\subsection{Template matching}

Template matching is a necessary step for group studies. Several reference
templates exist both for mouse and rat brains and the user needs to 
specify the path to the template of his choice to the \pythoninline{TemplateRegistrator}
class from the \pythoninline{registration} module.
%
% from Ionas et al
%In order to make any generalizable statements regard- ing brain function and organization, an equivalence between brain areas across individuals needs to be established. This is done by spatial transformation of brain maps in a study to a population or standard reference template.
%
%Several MRI templates exist for mouse
%on the estimation of a linear transform between the brain extracted images with AFNI's 3dAllineate, followed by the computation of a nonlinear warp between the whole head images with AFNI 3dQwarp.
%with spatial parameters adapted to the mouse brain
\begin{minted}[
frame=single,
framesep=2mm,
baselinestretch=1.2,
fontsize=\scriptsize,
]{python}
from sammba.registration import 
    TemplateRegistrator

registrator = TemplateRegistrator(
    'dorr_t2.nii.gz',
    brain_volume=400)
registrator.fit('mouse01_t1.nii.gz')
\end{minted}
We evaluated the registration accuracy of the proposed pipeline  on 
the publicly available Brookhaven in vivo dataset, consisting of 
T2-weighted images of 12 C57 male adult mice and
their segmentations in 20 brain regions \citep{ma2008vivo}. The scans were 
acquired using a 9.4 T Bruker scanner at 100 \textmu m isotropic resolution. The 
public dataset had incomplete files/segmentations for 2 subjects so the evaluation was 
limited to 10 subjects.
Because the shared individual images have been pre-registered to one reference image, 
we submitted them to slight random quadratic deformations (Normally 
distributed coefficients with std=$0.1$ mm for translation, $0.1$ degrees for 
rotation, $0.02$ mm for scaling, $0.02$ mm for shear and $0.005$ mm for the remaining $31$ polynomial coefficients) before performing the registration to the template.
%For each subject, we measured the correspondence of the segmented structures between the individual images after registration to the average template and the template itself.
We then measured the regional overlap
between each region in the average atlas and the transformed mice atlases 
using Dice similarity coefficient ($2\frac{|A \cap B|}{|A| + |B|}$) .
%
For comparison purposes, the registration was also performed using SPM mouse \citep{sawiak2009spmmouse}.
Figure ~\ref{fig:dices} shows that Sammba-MRI pipeline achieves
high overlap values and outperforms SPM mouse in the majority of cases.
\begin{figure}[h!]
\begin{center}
\includegraphics[width=85mm]{rois_on_template}
\end{center}
\caption{Registration to template of 10 C57 mice: \textbf{(A)} individual mouse anatomical image registered 
to the template with 
the contours of the average atlas superimposed as coloured lines; \textbf{(B)} Dice  
coefficient between each region in the average atlas and the transformed mice atlases 
(per region and animal).}\label{fig:dices}
\end{figure}

\subsection{Group-wise registration} % Creation of cohort-specific templates
% from Power
%Group-wise registration (GWR) aims to align all images within a common coordinate space, resulting in an average “atlas” image representing the mean group morphology, and deformation fields mapping each voxel to points in the original image space.
% from Feo
%An alternative method is creating a minimum deformation template, building the average brain that minimizes the required deformation to be adapted to the entire database of individual subjects (Veraart et al., 2011, Johnson et al., 2012, Kochunov et al., 2001, Ma et al., 2005). 

Group-wise registration aims to align all images within a common %coordinate
space, resulting in an average brain that represents the commonalities among
individual brain anatomies of a particular population.
%represents the mean group anatomy within a particular population.
%that is representative of a particular population
%extracts commonalities among individual brain anatomies and filters out idiosyncrasies.
%representation of average anatomy and a range of anatomical variation within a particular population
%
%represents the mean group morphology.
%extracts commonalities among individual brain anatomies and filters out idiosyncrasies.
%the methodology presented here provides means for creating an atlas that is representative of many individuals, 
%minimizes the required deformation to be adapted to the entire database of individual subjects \citep{kochunov2001regional, veraart2011population}
%(Johnson et al., 2012, veraart2011population, Kochunov et al., 2001, Ma et al., 2005).
The use of cohort-specific templates eliminates possible bias toward external
features and improves subsequent analyzes \citep{de2019towards}.
%The multi-level, iterative scheme (Fig 2.9) was described by Rohlfing et al. (2004) for bee brains, and then Kovačević et al. (2005) for mice – and adopted by many subsequent papers.
Sammba-MRI implements the multi-level, iterative scheme proposed by \citep{kovavcevic2005three}
%and adopted by many papers \citep{anderson2018small}
% proposes an iterative method
to create a fine anatomical 
template from individual structural MRI scans. A first rough template is obtained
by averaging bias corrected head images centred on their respective brain masks barycentres. Then the individual images are registered to this template.
This process of successive averaging/registration is iterated while increasing the number of degrees of 
freedom of the estimated transform and updating the target template (see \citep{nadkarni20193d} for a detailed description of the pipeline).
The method adapts to different small animal species, e.g. mouse lemurs
\citep{nadkarni2018digital}, and allows the creation of high quality
group average templates (Figure ~\ref{fig:mouse_template}).
\begin{figure}[h!]
\begin{center}
\includegraphics[width=85mm]{mouselemur_template}
\end{center}
\caption{Mouse lemur template from 34 animals.}\label{fig:mouse_template}
\end{figure}


%\section{Between-modalities registration}
\subsection{Multi-modal processing}

%TODO: remove where no example
In the context of the increasing use of multimodal imaging, several %modalities
MRI 
%and non MRI 
techniques 
can 
be acquired from small animals, including %and not restricted 
structural imaging with different contrasts, 
%or contrast agents,
%whether by endogenous or exogenous contrast
blood-oxygenation-level-dependent (BOLD) and  arterial spin labeling (ASL) MRI.
%, diffusion-weighted and chemical exchange saturation transfer (CEST) MRI, positron-emission tomography (PET) imaging.
%
%Magnetic resonance (MR) imaging is well known for its noninvasiveness and abundance of image contrasts. Conventional MR imaging contrasts are based on the spin relaxation rates of different body tissues under a static magnetic field and various radiofrequency (RF) pulses. Commonly encountered contrasts include T1, T2, proton density (PD), and T2* [1]. The search for novel image contrasts has been the ever-existing driving force in the MR research community, in order to gain further information on the body’s physiological and pathological conditions. Novel image contrasts have been developed by exploiting different aspects: physical or structural properties (diffusion-weighted imaging [2–4], MR elastography [5, 6], etc.); functional properties (perfusion [7, 8], BOLD [9, 10], resting state fMRI [11, 12], etc.); and chemical composition (MR spectroscopy [13, 14], chemical exchange saturation transfer (CEST) [15–22], etc.).
In addition to the inherent difficulties in intermodality registration \citep{ashburner1997multimodal},
%image artifacts or low resolution can alter
severe image artifacts can corrupt the non anatomical scan
resulting in a low signal-to-noise ratio (SNR).
For instance, the echo 
planar imaging (EPI) %is an ultrafast acquisition 
technique widely used in %diffusion imaging, 
functional MRI and perfusion imaging
suffers nonlinear geometric and intensity distortions caused by static magnetic field 
inhomogeneity that 
worsen at higher field strengths and have a more dramatic impact on small brains
\citep{hong2015evaluation}. 
%%High-field-strength scanners are more prone to the influence of disruptive artefact-generating factors

%Echo planar imaging (EPI) is an ultrafast acquisition technique widely used in diffusion imaging, functional MRI and perfusion imaging. However, it suffers from geometric and intensity distortions caused by static magnetic field inhomogeneity, which is worse at higher field strengths. Such susceptibility artifacts are particularly severe in relation to the small size of the mouse brain. 
%Among the image acquisition pulse sequences, echo planar imaging (EPI) is an ultrafast sequence widely applied to functional MRI (fMRI), diffusion imaging and perfusion imaging. It suffers from geometric and intensity distortions as well as signal dropouts that are caused by static magnetic field inhomogeneity [5], [6], particularly in the through plane direction due to the typically lower resolution than inplane. 
%The issue is especially severe in preclinical imaging. Firstly, the mouse brain is much smaller than the human brain. The same spatial extent of spin displacement affects a much larger portion of the mouse brain. Secondly, field inhomogeneity and hence distortions are proportional to the magnetic field strength. With rodent imaging typically performed at higher magnetic field strengths than human imaging, the artifacts worsen.
%Among the image acquisition pulse sequences, echo planar imaging (EPI) is an ultrafast sequence widely applied to functional MRI (fMRI), diffusion imaging and perfusion imaging. It suffers from geometric and intensity distortions as well as signal dropouts that are caused by static magnetic field inhomogeneity [5], [6], particularly in the phase-encoding direction due to the relatively low pixel bandwidth or in the through plane direction due to the typically lower resolution than inplane. The resultant global and regional distortions are commonly seen near the air-tissue or bone-tissue interfaces, where magnetic susceptibility changes rapidly. The issue is especially severe when translating similar methods to transgenic mouse models to understand disease mechanisms and drug effects. Firstly, the mouse brain is much smaller than the human brain. The same spatial extent of spin displacement affects a much larger portion of the mouse brain. Secondly, field inhomogeneity and hence distortions are proportional to the magnetic field strength. With rodent imaging typically performed at higher magnetic field strengths than human imaging, the artifacts worsen. The geometric distortion will result in localization errors, difficulty in image registration and hence group analysis. The intensity distortion in EPI could also bias the quantitative measures such as relaxivity, diffusivity and perfusion, since quantification of these metrics usually involves nonlinear fitting of the EPI series.
%Among the image acquisition pulse sequences, echo planar imaging (EPI) is an ultrafast sequence widely applied to functional MRI (fMRI), diffusion imaging and perfusion imaging. It suffers from geometric and intensity distortions as well as signal dropouts that are caused by static magnetic field inhomogeneity [5], [6], particularly in the phase-encoding direction due to the relatively low pixel bandwidth or in the through plane direction due to the typically lower resolution than inplane. The resultant global and regional distortions are commonly seen near the air-tissue or bone-tissue interfaces, where magnetic susceptibility changes rapidly. The issue is especially severe when translating similar methods to transgenic mouse models to understand disease mechanisms and drug effects. Firstly, the mouse brain is much smaller than the human brain. The same spatial extent of spin displacement affects a much larger portion of the mouse brain. Secondly, field inhomogeneity and hence distortions are proportional to the magnetic field strength. With rodent imaging typically performed at higher magnetic field strengths than human imaging, the artifacts worsen. The geometric distortion will result in localization errors, difficulty in image registration and hence group analysis. The intensity distortion in EPI could also bias the quantitative measures such as relaxivity, diffusivity and perfusion, since quantification of these metrics usually involves nonlinear fitting of the EPI series.
%One could reduce the signal dropouts seen in gradient echo imaging by incorporating slice shimming, also known as the z-shim technique, into the pulse sequence [7], [8], [9]. However this will prolong the image acquisition time depending on how many z-shim steps used. Spin-echo based acquisition, which is less sensitive to field inhomogeneity, could help to reduce the distortion. However, even with spin-echo EPI (SE-EPI), the geometric and intensity distortions are still significant at high field strengths. The artifact is also echo time (TE) dependent; however, ultrashort TE is difficult to achieve with EPI. Another way is to reduce the echo train length by increasing the bandwidth or using partial Fourier, at the cost of lower SNR and/or spatial resolution. Echo train length can also be reduced by multi-shot EPI, but the acquisition time will be longer and the phase error between shots would introduce additional artifacts. Applying localized susceptibility matching materials near the air/bone-tissue interfaces can reduce the regional magnetic inhomogeneity, though it will be difficult for regions away from the skin [10]. Alternatively, postprocessing methods can be applied to reduce the distortions.
%Several EPI distortion correction algorithms have been proposed and demonstrated successfully in human studies at lower fields. The most common way is based on magnetic field mapping. A field map, measured by the phase differences of two gradient echo images acquired with different TEs, describes the spatial variation of the magnetic field, from which a voxel displacement map can be calculated and used to unwrap the distorted EPI images [11], [12]. The main drawback of this technique is the separate acquisition of the multiecho images. Subject movement between the field mapping and EPI acquisition could render the field map inaccurate. In addition, the phase unwrapping process is sensitive to noise; therefore the field map in regions of low SNR is unreliable. Alternatively, one can acquire a phase-encoded multi-reference scan to estimate the magnitude and phase errors due to the field inhomogeneity, and then use that to correct the EPI artifact [13].
%Geometric distortions can also be corrected for by nonlinear registration to an anatomically correct image, typically acquired by fast spin echo (FSE). The deformation field could be calculated by minimizing the least squared differences of intensity [14] or log-intensity [15] between the distorted EPI and anatomical images. The undistortion performance highly depends on the registration algorithm, implementation, and parameter optimization. Besides, it only corrects for geometric distortion but not the intensity distortion, which may still result in quantification error.

Intra-subject registration between an anatomical scan and another modality
is handled through the \pythoninline{Coregistrator} class from the
\pythoninline{registration} module. 
%Correction for geometric distortions is performed 
\begin{minted}[frame=single, framesep=2mm, baselinestretch=1.2,
fontsize=\scriptsize,]{python}
from sammba.registration import 
    Coregistrator
coregistrator = Coregistrator(
    brain volume =400)
\end{minted}
%\subsubsection{Registration with anatomical}

\subsubsection{Rigid-body registration}
Since orientation is correctly handled through the DICOM to NIfTI conversion,
the anatomical image is first reoriented to match the modality of interest.
Both images then undergo intensity unifization and brain extraction.
A rigid body
transform that minimizes normalized mutual information
between the brain extracted images is finally estimated and applied to the whole head images.

\begin{minted}[frame=single, framesep=2mm, baselinestretch=1.2,
fontsize=\scriptsize,]{python}
coregistrator.fit_anat(
    'mouse01_t1.nii.gz')
coregistrator.fit_modality(
    'mouse01_t2.nii.gz')
\end{minted}
\subsubsection{Reorientation-only}

It is possible that the source or/and the reference
images are of insufficient quality to correctly estimate a rigid body transform
%(see figure ...)
. In this case,
assuming that the head motion between the two acquisitions is low, it is better
to only reorient the anatomical image to match the modality of interest.
\begin{minted}[frame=single, framesep=2mm, baselinestretch=1.2,
fontsize=\scriptsize,]{python}
coregistrator.fit_anat('mouse01_t1.nii.gz')
coregistrator.fit_modality(
    'mouse01_t2.nii.gz',
    reorient_only=True)
\end{minted}

\subsubsection{Resting state BOLD fMRI processing}

BOLD scans are preprocessed using the same usual steps for human data
with optional slice timing correction, bias field correction, realignment to the 
first volume
and computation of the temporal mean of all the volumes.
The corresponding structural scan is then registered to the average BOLD scan.
Since this is a critical step, the user can choose
either to pursue with human-like pipeline by estimating a rigid body functional-to-
structural transform and applying its inverse to the structural image, or to assume 
that the head motion between the two scans is negligible.
In all cases, the transformed or not structural image is then reoriented
to match the functional image. Next, the average functional image and
the reoriented structural image are
splitted into 2D slices along the z-direction and each functional slice undergoes
 a nonlinear registration step to best match the corresponding structural slice.
This perslice registration corrects for EPI distortion while being more conservative 
than a global 3D nonlinear registration, to compensate for the low SNR in the BOLD acquisition of small animals.
Since geometric distortions are higher in the through plane direction due to the typically lower resolution than inplane, the correction is still satisfying.

%
\subsubsection{ASL fMRI processing}

ASL is an attractive method 
to image the vascular system by directly measuring blood flow.
%ASL MRI is therefore the method of choice for quantification of capillary blood flow in small animals.
However, estimating the cerebral blood flow (CBF) in small animals is challenging due 
to the low SNR and lack of sensitivity \citep{kober2008experimental}.
Sammba-MRI allows to preprocess functional ASL scans with the M0 scan used 
as the representative volume for registration. 
No %slice timing correction nor 
between volume realignment is performed because of the usual poor SNR.
For Bruker-FAIR (Flow-sensitive Alternating Inversion Recovery) EPI sequences,
quantitative   CBF   maps can be estimated using \pythoninline{fair_to_proc} 
function from the \pythoninline{modality_processor} module.

\subsection{Modality to template and vice versa}

BOLD and ASL preprocessing can be performed in the individual space with
\pythoninline{Coregistrator} or in template space with \pythoninline{TemplateRegistrator}.
In the latter case, the structural-to-template warp, the functional-to-structural 
rigid body transform and the perslice functional-to-structural warps are %finally 
combined 
 and applied in a one-big-step transformation
to the functional data to minimize interpolation errors.
The \pythoninline{TemplateRegistrator} class encompasses an 
\pythoninline{inverse_transform_towards_modality}
 to bring an image from the reference space to the individual's space.

%Once a registrator has been transformed, the inverse operation bringing an image from the reference space to the individual's space can be readily performed using the associated inverse transform function.

%registrator = TemplateRegistrator(
%    'dorr_t2.nii.gz',
%    brain_volume='400')
%registrator.fit_anat(
%    'mouse01_t1.nii.gz')
%\begin{minted}[frame=single, framesep=2mm, baselinestretch=1.2,
%fontsize=\scriptsize,]{python}
%registrator.fit_modality(
%    'mouse01_epi.nii.gz',
%    modality='func')
%registrator.inverse_transform_towards_modality(
%    'dorr_atlas.nii.gz')
%\end{minted}

\subsection{Results}

Resting state fMRI allows to study temporally synchronized BOLD oscillations
reflecting functionally connected brain networks.
As in human resting state fMRI, spatial networks can be extracted using Independent Components Analysis (ICA) 
and were successfully demonstrated in anaesthetized mice \citep{zerbi2015mapping, grandjean2019common}. 
We preprocessed the publicly shared functional data
from 15 mice (2-3 months old) from \citet{zerbi2015mapping} paper with Sammba-MRI and performed a group ICA 
\citep{varoquaux2010group}. Relevant bilateral
regions were found without additional data post-processing Figure ~\ref{fig:ica}.
\begin{figure}[h!]
\begin{center}
\includegraphics[width=85mm]{{ica}}
\end{center}
\caption{Bilateral ICA components}
\label{fig:ica}
\end{figure}
To illustrate the perfusion processing pipeline, we used perfusion FAIR images from 10 C57BL/6J mice (5-7 months)
to quantify CBF.
Figure ~\ref{fig:cbf} shows voxelwise map averaged across all individuals and regional absolute CBF values, all 
in agreement with the literature \citep{muir2008cerebral}.
%Our implementation processes 10 mice, more than 300Gb, in only 20 minutes (regular desktop, 8Gb of RAM) [1 mice with 30 volumes, resolution, number of slices etc].
\begin{figure}[h!]
\begin{center}
\includegraphics[width=85mm]{cbf}
\end{center}
\caption{CBF from 10 C57 mice in ml/100g/min:  \textbf{(A)} group   average   CBF   map ;  \textbf{(B)} individual regional CBF.}\label{fig:cbf}
\end{figure}
\section{Big data, reproducibility, collaboration}
The package design facilitates big data exploration: the user is able to run an 
entire analysis in a single Python script, rerunning pipelines is optimized 
through Nipype caching mechanism and long lasting steps (nonlinear warping, perfusion 
fitting) are executed in parallel.
%
We believe that reproducibility in the neuroimaging field is not possible without
making the acquired images and the preprocessing code available to the community.
%
%With the aim of promoting the sharing of animal brain MRI data, 
For this reason, Sammba-MRI promotes the sharing of MRI data by providing 
%additional 
utility functions to download public small animal brain MRI 
datasets and relies on it for demoing the package capabilities.
In order to encourage external contributions, our library source code is hosted on the open 
collaborative GitHub platform
%Community-driven development. We base our development on collaborative tools such as git, github
and distributed under the CeCILL v2.1 license, a FOSS license adapted to both international and French legal matters 
allowing anyone to make changes and redistribute it. 
Sammba-MRI supports GNU/Linux and Mac OS X operating systems (OS), used by over 70\% 
of neuroimagers \citep{hanke2011neuroscience}. 

%It has not been tested on Windows because FSL recommends a Unix based OS.

%We focus on ease-of-use and code readability in order to encourage external contributions, 

%With this aim, Sammba-MRI is hosted on the open collaborative GitHub platform
%
%Community-driven development. We base our development on collaborative tools such as git, github
%
%This Agreement is an open source software license intended to give users significant freedom to modify and redistribute the software licensed hereunder.
%
%a "Free Software" license by the FSF with which the CeCILL project founders have worked. Since version 2.1, CeCILL is also approved by the Open Source Initiative as an "Open Source" license
%
%We believe that reproducibility is enabled [enhanced] with the sha. With the aim of promoting the sharing of animal brain MRI data, Sammba-MRI provides additional utility functions to download publicly available small animal neuroimaging  datasets.


\section{Conclusion}

By efficiently combining different existing human and animal neuroimaging
tools, Sammba-MRI allows to tackle common processing issues in a fully
automated fashion. High quality spatial registration can be easily performed, 
including template matching, between modalities registration as well as
the creation of cohort-specific templates. Sammba-MRI also implements
functional and perfusion MRI preprocessing methods and cerebral blood flow
estimation for FLAIR perfusion images. Emphasis is put on code readability
and ease of use to favour contributions from the community.

\section*{Conflict of Interest Statement}

The authors declare that the research was conducted in the absence
of any commercial or financial relationships that could be construed
as a potential conflict of interest.

\section*{Author Contributions}

SB, NN and MC contributed code to the project. NN, CG and MD contributed
to data acquisition. SB wrote the manuscript with input from CG and NN.
Every author read and approved the manuscript.

\section*{Funding}

We thank the France-Alzheimer Association, Plan Alzheimer Foundation
and the French Public Investment Bank's "ROMANE" program for funding this study.

\section*{Data Availability Statement}

The mouse lemur dataset can be automatically loaded through Sammba-MRI. The perfusion
dataset will be made publicly available following publication.

% Please see the availability of data guidelines for more information, at https://www.frontiersin.org/about/author-guidelines#AvailabilityofData

\bibliographystyle{frontiersinSCNS_ENG_HUMS} 

\bibliography{sammba}

\end{document}
